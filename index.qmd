---
title: "PRACTICAS"
author: "Diego Guanotasig"
date: "04-10-25"
format: html
jupyter: python3
---

# MIERCOLES 08

```{python}
import pandas as pd
import requests
 
# Natural Language Toolkit
import nltk
# downloading some additional packages and corpora
nltk.download('punkt_tab') # necessary for tokenization
nltk.download('wordnet') # necessary for lemmatization
nltk.download('stopwords') # necessary for removal of stop words
nltk.download('averaged_perceptron_tagger_eng') # necessary for POS tagging
nltk.download('maxent_ne_chunker' ) # necessary for entity extraction
nltk.download('omw-1.4') # necessary for lemmatization
nltk.download('words')

```

```{python}
url = "https://raw.githubusercontent.com/erickedu85/dataset/master/story.txt"
r = requests.get(url)
r.encoding = 'utf-8'

story = r.text
story
```

```{python}
from nltk import word_tokenize, pos_tag
word = word_tokenize(story)
word[:20] 
```

```{python}
from nltk.stem import PorterStemmer as stemer
from nltk.stem import WordNetLemmatizer as lematizer



```

```{python}
from nltk import pos_tag
pos = pos_tag(word)
pos[:20]
```
```{python}
from nltk.corpus import stopwords as stop
stopwords = stop.words("english")
stopwords[:20]

#for item in stop.words("spanish"):
#print(item)
```

# stop word in story
```{python}
tokens = nltk.word_tokenize(story.lower())

# limpiexa depende del contexto
# limpieza de numeros
lettertokens = [word for word in tokens if word.isalpha()]

withot_stopwords = [word for word in lettertokens if word.lower()]
withot_stopwords[:20]

```



